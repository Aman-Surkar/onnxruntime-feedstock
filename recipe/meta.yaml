{% set name = "onnxruntime" %}
{% set version = "1.13.1" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - git_url: https://github.com/microsoft/onnxruntime
    git_rev: v{{ version }}
    patches:
      - 0001-Fix-for-tests-failures-with-cuda-build-type.patch       #[build_type=='cuda']
      - 0001-Fix-for-NVCC-error.patch                                #[build_type=='cuda']
  - url: https://github.com/onnx/onnx/archive/f7ee1ac60d06abe8e26c9b6bbe1e3db5286b614b.zip
    sha256: aaee93635e2561f091f4ae007b0a6155b665cc43f72570bb9ff3279b578add1e
    folder: onnx
  - url: https://gitlab.com/libeigen/eigen/-/archive/d10b27fe37736d2944630ecd7557cefa95cf87c9/eigen-d10b27fe37736d2944630ecd7557cefa95cf87c9.tar.gz
    sha256: a3c10a8c14f55e9f09f98b0a0ac6874c21bda91f65b7469d9b1f6925990e867b
    folder: eigen
  - url: https://github.com/NVlabs/cub/archive/c3cceac115c072fb63df1836ff46d8c60d9eb304.zip
    sha256: 8894c68d7549681591c34078dcd40cf34459b6c7d33407f07e2145d2adb683ee 
    folder: cub
  - url: https://github.com/nlohmann/json/archive/b5364faf9d732052506cefc933d3f4e4f04513a5.zip
    sha256: 91d738fa41106dea869819911f97265e8d2c765c2049478bc0c1c845ec3afbbd
    folder: json
  - url: https://github.com/pytorch/cpuinfo/archive/5916273f79a21551890fd3d56fc5375a78d1598d.zip
    sha256: 2a160c527d3c58085ce260f34f9e2b161adc009b34186a2baf24e74376e89e6d 
    folder: cpuinfo

build:
  number: 1
  string: h{{ PKG_HASH }}_{{ build_type }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }}   #[build_type == 'cpu']
  string: h{{ PKG_HASH }}_{{ build_type }}{{ cudatoolkit | replace(".*", "") }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} #[build_type == 'cuda']
  script_env:
    - CUDA_HOME      #[build_type == 'cuda']

requirements:
  build:
    - {{ compiler('c') }}     # [ppc_arch != "p10"]
    - {{ compiler('cxx') }}   # [ppc_arch != "p10"]
    - cmake {{ cmake }}
    - libprotobuf {{ protobuf }}
    - boost_mp11 {{ boost_mp11 }}
    - gmock {{ gmock }}
    - gtest {{ gmock }}
    - optional-lite {{ optional_lite }}
    - nlohmann_json {{ nlohmann_json }}
    - safeint {{ safeint }}
    - libdate {{ libdate }}
    {% if build_type == 'cuda' %}
    - cudatoolkit {{ cudatoolkit }}
    - cudnn {{ cudnn }}
    {% endif %}

  host:
    - python {{ python }}
    - pip
    - wheel
    - flake8
    - flatbuffers {{ flatbuffers }}
    - python-flatbuffers {{ flatbuffers }}
    - coloredlogs
    - packaging
    - sympy
    - re2
    - nsync
    - libprotobuf {{ protobuf }}
    # We need to statically link protobuf until we link against a system libonnx
    # See: https://github.com/conda-forge/onnxruntime-feedstock/issues/5
    - libprotobuf-static {{ protobuf }}
    - numpy {{ numpy }}
    - pybind11
    - ninja {{ ninja }}

  run:
    - python {{ python }}
    - numpy {{ numpy }}
    - protobuf {{ protobuf }}
    - python-flatbuffers {{ flatbuffers }}
    - coloredlogs
    - packaging
    - sympy
    {% if build_type == 'cuda' %}
    - cudatoolkit {{ cudatoolkit }}
    - cudnn {{ cudnn }}
    {% endif %}

test:
  imports:
    - onnxruntime
  commands:
    - pip check
  requires:
    - pip

about:
  home: http://onnxruntime.ai/
  summary: cross-platform, high performance ML inferencing and training accelerator
  license: MIT
  license_file:
    - LICENSE
    - cmake/external/onnx/LICENSE
  description: |
    ONNX Runtime is a cross-platform inference and training machine-learning accelerator.
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://github.com/microsoft/onnxruntime/tree/master/docs

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
